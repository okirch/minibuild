#!/usr/bin/python3
#
# This is a simplistic build script for building artefacts of various
# programming languages natively (eg using pip, npm etc) and upload the
# resulting artefacts to a local repo.
#
#   Copyright (C) 2020 Olaf Kirch <okir@suse.de>
#
#   This program is free software; you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation; either version 2 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
#

import sys
import os
import os.path
import io
import pkginfo
import glob
import shutil
import brcoti_core

SCRIPT_NAME = sys.argv[0]

DEFAULT_BUILD_COMPUTE = "podman"

def create_build_engine(config):
	opts = config.command_line_options
	return brcoti_core.Engine.factory(opts.engine, config)

def create_compute_backend(config, default_backend):
	backend_name = config.command_line_options.compute or default_backend
	return brcoti_core.Compute.factory(backend_name, config)

def source_from_path(name, config):
	if os.path.isdir(name):
		print("=== Using source directory %s ===" % name)
		return brcoti_core.Engine.create_source_from_local_directory(name, config)

	engine = create_build_engine(config)

	print("=== Using file %s (build engine %s) ===" % (name, engine.name))
	source = engine.create_source_from_local_file(name)

	# DownloadFinder will never return an sdist that
	# requires a python version incompatible with ours.
	# For an sdist provided directly on the command line,
	# it might be nice to check for this explicitly, but that's a
	# lot of work. Not the least because many sdist tarballs
	# do not contain structured build information, but provide
	# a more or less messy setup.py

	return source

def find_source(engine, req_string, use_git = False):
	print("=== Locating %s ===" % (req_string,))
	req = engine.parse_build_requirement(req_string)

	sdist = engine.build_source_locate(req)

	if sdist is None:
		print("FAILED to locate source for %s" % req)
		return None

	# By default, if the engine finds that a source artefact comes
	# with a git url, it will try to build directly from git.
	if not use_git:
		sdist.git_repo_url = None

	return brcoti_core.SourceFile(sdist, engine)

class BuildJob(object):
	def __init__(self, config, engine, compute_backend, source):
		self.config = config
		self.engine = engine
		self.compute_backend = compute_backend
		self.source = source
		self.build = None
		self.build_state = self.engine.build_state_factory(source)

		self.always_commit = False
		self.quiet = False
		self.rebuild_if_needed = False
		self.shell_on_fail = False
		self.auto_repair = False

	def id(self):
		return self.source.id()

	def source_for(self, build):
		spec = self.source.info

		assert(len(spec.sources) == 1)
		return spec.sources[0]

	def rebuild_required(self):
		if not self.rebuild_if_needed:
			return True

		print("=== Checking whether a rebuild is required ===")
		if not self.build_state.rebuild_required():
			print("=== No rebuild required for %s ===" % self.id())
			return False

		return True

	# This is a prep task
	# Merge explicit requirements given on the command line as
	#  --require rpm:foo,bar,baz --require ruby:bundler,rake
	def merge_cmdline_requirements(self, opt_list):
		spec = self.source.info

		for s in opt_list:
			if ':' not in s:
				raise ValueError("--require argument must be of the form \"engine:name,name,...\" (%s)" % s)

			(engine_name, rest) = s.split(':', 1)

			engine = brcoti_core.Engine.factory(engine_name)

			for req in rest.split(','):
				req = engine.parse_build_requirement(req)
				req.origin = 'commandline'
				spec.add_requirement(req)

	# This is a prep task
	# Set the build strategy from the --strategy command line options, such as
	#  --strategy 'bundler(gem-build())'
	def set_cmdline_strategy(self, arg):
		if not arg or arg == 'auto':
			return

		self.source.info.build_strategy = brcoti_core.BuildStrategy.parse(self.engine, arg)

	# This is a prep task - eg ruby would look at the upstream artefact
	# and scan it for :development dependencies
	def anticipate_build_dependencies(self):
		spec = self.source.info

		dep_list = []
		for sdist in spec.sources:
			dep_list += self.engine.infer_build_requirements(sdist)

		if dep_list:
			print("Inferred build requirement(s) from package:")
			for dep in dep_list:
				print("  %s" % dep.format())

			spec.requires += dep_list

	def unpack_source(self):
		print("=== Unpacking %s ===" % self.id())
		build_info = self.source.info

		print("Validating build info")
		self.engine.validate_build_info(build_info, auto_repair = self.auto_repair)

		# Download the source archive if we don't have it yet
		for sdist in build_info.sources:
			# FIXME: how do we make sure we use the right downloader here? 
			if sdist.url and not sdist.git_url():
				self.engine.downloader.download(sdist)

		# spawn a container/VM or whatever compute node we need
		compute_node = self.engine.prepare_environment(self.compute_backend, build_info)

		try:
			self.build = self.engine.build_unpack(compute_node, build_info, self.auto_repair)
		except brcoti_core.UnsatisfiedDependencies as e:
			print("Cannot build %s: missing build dependencies:" % self.id())
			for req in e.dependencies:
				print("  %s" % req.format())

			if e.remedy:
				print("")
				print("Suggested remedy")
				e.remedy.display()

			raise e

		self.build.set_logging(self.quiet, self.build_state.build_log_file())
		return self.build

	def build_package(self):
		print("=== Building %s ===" % self.id())
		build = self.build

		build_strategy = self.source.info.build_strategy
		if build_strategy is None:
			build_strategy = self.engine.create_build_strategy_default()
		self.build_strategy = build_strategy

		try:
			artefacts = build.build(build_strategy)
		except brcoti_core.BuildFailure as e:
			if not self.shell_on_fail:
				raise e

			print("*** BUILD FAILURE ***")
			print(e)
			print("Opening interactive shell for debugging")
			self.build.compute.interactive_shell(working_dir = e.cmd.working_dir)
			raise brcoti_core.BuildAborted()

		if not artefacts:
			raise ValueError("%s: nothing got built" % self.source.id())

		return artefacts

	def process_build_dependencies(self):
		print("=== Inspecting build dependencies ===")
		build = self.build

		build.guess_build_dependencies(self.build_strategy)

		requires = self.engine.finalize_build_depdendencies(build)

		if requires:
			print("Build requirements:")
			for req in requires:
				print("  %s" % (req, ))

	def prepare_results(self):
		print("=== Collecting build results ===")
		build = self.build

		build.prepare_results(self.build_state)

	def compare_upstream(self):
		print("=== Comparing our build to upstream artefact(s) ===")
		engine = self.engine
		build = self.build

		retval = True
		for mine in build.build_info.artefacts:
			# The version of the artefact we built may not be what we
			# started with. Some gems append the build date to the
			# package version. In other cases (eg when building a compiled
			# native ruby extension), the version will include the platform
			# (such as x86_linux)
			#
			# Therefore, we need to use the version number of the package
			# we started from.
			sdist = self.source_for(mine)

			if sdist.id() != mine.id():
				print("  Comparing %s to upstream %s" % (mine.id(), sdist.id()))

			req_string = "%s == %s" % (sdist.name, sdist.version)
			print("Trying to find upstream build for %s" % req_string)
			req = engine.parse_build_requirement(req_string)

			finder = engine.create_binary_download_finder(req, verbose = False)
			upstream = finder.get_best_match(engine.upstream_index)
			if not upstream:
				raise ValueError("No upstream build for %s" % req_string)

			# The artefact was returned by an index; it's a bug to not be attached
			# the a cache
			assert(upstream.cache)

			path = engine.downloader.download(upstream)

			# This returns an ArtefactComparison object
			result = build.compare_build_artefacts(path, mine.local_path)

			if result:
				# Our build is identical with upstream
				continue

			print("%s differs from upstream build" % mine.id())
			result.print()

			print("--- showing diff ---")
			result.show_diff()
			print("--- end diff ---")
			print("")

			retval = False

		if retval:
			print("Our build matches upstream")
		return retval

	# This is a prep task.
	# After a successful build, we inspect the list of packages that got installed
	# automatically (eg via pip wheel or bundler install) and check them against
	# our local index.
	def verify_artefact_availability(self, artefact_list):
		self.engine.validate_used_packages(artefact_list, merge_from_upstream = self.auto_repair)

	def maybe_commit(self):
		print("=== Checking whether artefacts changed from previous build ===")
		build_state = self.build_state
		build = self.build

		if not self.always_commit and build.unchanged_from_previous_build(build_state):
			print("Artefacts have not changed since previous build")
			return

		uploader = self.engine.uploader
		if uploader:
			print("=== Uploading build results to %s ===" % uploader.describe())
			for p in build.artefacts:
				uploader.upload(p)

		build_state.commit()
		build.cleanup()

		build_state.cleanup()
		self.build_state = None

def prep_action(config, opts):
	engine = create_build_engine(config)

	# Allow to override on the command line?
	compute_backend = create_compute_backend(config, DEFAULT_BUILD_COMPUTE)

	exit_code = 0
	for name in opts.packages:
		# We want to build using upstream. This selects the upstream package repo
		# and disables the proxy.
		engine.use_upstream()

		if os.path.isfile(name):
			source = source_from_path(name, config)
		else:
			source = find_source(engine, name, use_git = opts.git)
		if source is None:
			exit_code = 1
			continue

		sdist = source.info.sources[0]

		url = sdist.git_url()
		if not url:
			url = sdist.url
		if url:
			print("Using %s" % url)

		source.info.build_strategy = engine.create_build_strategy("auto")

		print("=== Package %s ===" %(source.id()))
		job = BuildJob(config, engine, compute_backend, source)
		job.quiet = opts.quiet
		job.shell_on_fail = opts.shell_on_fail
		job.auto_repair = opts.auto_repair

		job.merge_cmdline_requirements(opts.require)
		job.set_cmdline_strategy(opts.strategy)

		try:
			job.anticipate_build_dependencies()
			job.unpack_source()
			job.build_package()
			job.process_build_dependencies()
			job.prepare_results()
			if opts.no_upstream_check:
				print("*** Skipping upstream check. ***")
			elif not job.compare_upstream():
				warnmsg = '''

        W   W    A    RRR  N   N II N   N  GGG   !!
        W   W   A A   R  R NN  N II NN  N G      !!
        W W W  AAAAA  RRR  N N N II N N N G  GG  !!
         W W  A     A R  R N  NN II N  NN  GGG   **

Our build seems to differ from the upstream build, which most likely means we did not
build it correctly.
If our build *IS* correct, and this warning is due to a bug, please fix the mis-detection.
If you're in a hurry, re-run this command with --no-upstream-check
'''
				print("=== WARNING: DIFFERS FROM UPSTREAM ===")
				print(warnmsg)
				print("=== WARNING: DIFFERS FROM UPSTREAM ===")
				exit_code = 1

			# job.maybe_commit()

		except brcoti_core.BuildAborted:
			print("Build of %s ABORTED" % sdist.id())
			exit_code = 1
		except Exception as e:
			print("FAILED to build %s" % sdist.id())
			import traceback
			print(e)
			traceback.print_tb(sys.exc_info()[2])
			traceback.format_exc()
			exit_code = 1

		if job.build:
			write_source_dir(name, source.info, job.build.build_info)

			engine.reset_indices()
			job.verify_artefact_availability(job.build.build_info.used)

	print("=== Done ===")

	# In case anyone would ever entertain the idea of mixing calls to prep_action
	# with other actions within a single run.
	engine.reset_indices()

	return exit_code

def write_source_dir(name, source_info, build_info):
	src_dir = name
	if os.path.isdir(src_dir):
		shutil.rmtree(src_dir)
	os.makedirs(src_dir, mode = 0o755)
	for sdist in source_info.sources:
		if sdist.local_path is not None:
			shutil.copy(sdist.local_path, src_dir)

	info = source_info
	info.requires += build_info.requires

	info_path = os.path.join(src_dir, "build-info")
	info.save(info_path)

	info_path = os.path.join(src_dir, "build-used")
	build_info.save(info_path)

def submit_action(config, opts):
	exit_code = 0
	for name in opts.packages:
		print("Examining %s" % name)

		if not os.path.isdir(name):
			print("Cannot submit %s: must be a local directory" % name)
			exit_code = 1
			continue

		print("=== Using source directory %s ===" % name)
		source = brcoti_core.Engine.create_source_from_local_directory(name, config)

		engine = brcoti_core.Engine.factory(source.info.engine)
		if not engine:
			print("%s: build-info specifies invalid engine \"%s\"" % (name, source.info.engine))
			exit_code = 1
			break

		engine.submit_source(source)

	print("=== Done ===")
	return exit_code

def build_action(config, opts):
	compute_backend = create_compute_backend(config, DEFAULT_BUILD_COMPUTE)

	exit_code = 0
	for name in opts.packages:
		print("Examining %s" % name)

		source = source_from_path(name, config)
		if source is None:
			exit_code = 1
			continue

		engine = brcoti_core.Engine.factory(source.info.engine)

		print("=== Package %s ===" %(source.id()))
		job = BuildJob(config, engine, compute_backend, source)
		job.always_commit = opts.force
		job.quiet = opts.quiet
		job.rebuild_if_needed = opts.rebuild_if_needed
		job.shell_on_fail = opts.shell_on_fail
		job.auto_repair = opts.auto_repair

		try:
			if not job.rebuild_required():
				continue

			job.unpack_source()
			job.build_package()
			job.process_build_dependencies()
			job.prepare_results()

			if opts.upstream_check and not job.compare_upstream():
				warnmsg = '''

        W   W    A    RRR  N   N II N   N  GGG   !!
        W   W   A A   R  R NN  N II NN  N G      !!
        W W W  AAAAA  RRR  N N N II N N N G  GG  !!
         W W  A     A R  R N  NN II N  NN  GGG   **

Our build seems to differ from the upstream build, which most likely means we did not
build it correctly.
If our build *IS* correct, and this warning is due to a bug, please fix the mis-detection.
'''
				print("=== WARNING: DIFFERS FROM UPSTREAM ===")
				print(warnmsg)
				print("=== WARNING: DIFFERS FROM UPSTREAM ===")
				exit_code = 1

			job.maybe_commit()

		except brcoti_core.BuildAborted:
			print("Build of %s ABORTED" % source.id())
			exit_code = 1
		except brcoti_core.UnsatisfiedDependencies as e:
			print("Build of %s has unsatisfied dependencies" % source.id())
			for req in e.dependencies:
				print("  %s" % req.format())

			print("In order to merge these from upstream, run the following command:")
			print("%s merge-extra %s" % (SCRIPT_NAME,
					" ".join(["'%s:%s'" % (r.engine, r.format()) for r in e.dependencies])))
		except Exception as e:
			print("FAILED to build %s" % source.id())
			import traceback
			print(e)
			traceback.print_tb(sys.exc_info()[2])
			traceback.format_exc()
			exit_code = 1

	print("=== Done ===")
	return exit_code

def mkindex_action(config, opts):
	engine = brcoti_core.Engine.factory(opts.engine)

	print("=== Publishing %s build results ===" % engine.name)
	engine.publish_build_results()

	print("=== Done ===")
	return 0

def merge_extra_action(config, opts):

	by_engine = dict()
	for name in opts.packages:
		(engine_name, req_string) = name.split(':', 1)

		req_list = by_engine.get(engine_name)
		if req_list is None:
			req_list = []
			by_engine[engine_name] = req_list

		req_list.append(req_string)

	for (engine_name, req_list) in by_engine.items():
		print("=== Merging %s packages from upstream ===" % engine_name)
		engine = brcoti_core.Engine.factory(engine_name)

		req_list = [engine.parse_build_requirement(req_string) for req_string in req_list]

		engine.merge_from_upstream(req_list)
		# engine.publish_build_results()

	print("=== Done ===")
	return 0

def build_option_parser():
	import argparse

	parser = argparse.ArgumentParser(prog = "minibuild",
		description = "Build artefacts for various native package managers")

	parser.add_argument('--config', default = [], action = 'append',
		help = "Path to configuration file")

	parser.add_argument('--engine', default = "python3",
		help = "Build engine to use (defaults to python3)")

	parser.add_argument('--debug', default = False, action = 'store_true',
                help = "Enable debugging output")
	parser.add_argument('--quiet', default = False, action = 'store_true',
                help = "Be less verbose")

	parser.add_argument('--compute', default = None,
		help = "Compute backend to use (default is dependent on the action)")

	subparsers = parser.add_subparsers(dest="action",
		title = "action")

	prep_parser = subparsers.add_parser('prep',
		help = "Prepare new source package")

	prep_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")
	prep_parser.add_argument('--git', default = False, action = 'store_true',
                help = "Build from git repo rather than sdist")
	prep_parser.add_argument('--no-upstream-check', default = False, action = 'store_true',
                help = "Do not compare our build results to upstream build (use with caution)")
	prep_parser.add_argument('--shell-on-fail', default = False, action = 'store_true',
                help = "When a build command fails, open an interactive shell session to debug the issue")
	prep_parser.add_argument('--auto-repair', default = False, action = 'store_true',
                help = "Try to detect and fix build environment issues")
	prep_parser.add_argument('--require', default = [], action = 'append',
                help = "List explicit build dependencies such as 'rpm:gcc-c++'")
	prep_parser.add_argument('--strategy', default = None,
                help = "Specify a build strategy like 'bundler(gem-build())' (default: auto)")

	submit_parser = subparsers.add_parser('submit',
		help = "Submit source package(s)")
	submit_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")

	build_parser = subparsers.add_parser('build',
		help = "Build package(s)")
	build_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")
	build_parser.add_argument('--rebuild-if-needed', default = False, action = 'store_true',
                help = "Only rebuild package if needed")
	build_parser.add_argument('--force', default = False, action = 'store_true',
                help = "Always store build results, even if they did not change")
	build_parser.add_argument('--upstream-check', default = False, action = 'store_true',
                help = "Compare our build results to upstream build (use with caution)")
	build_parser.add_argument('--shell-on-fail', default = False, action = 'store_true',
                help = "When a build command fails, open an interactive shell session to debug the issue")
	build_parser.add_argument('--auto-repair', default = False, action = 'store_true',
                help = "Try to detect and fix build environment issues")

	mkindex_parser = subparsers.add_parser('make-index',
		help = "Rebuild package index")
	mkindex_parser.add_argument('--destdir', default = None,
		help = "Specify the destination directory (defaults to working directory)")

	merge_parser = subparsers.add_parser('merge-extra',
		help = "Merge extra binary packages from upstream")
	merge_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")

	return parser

opts = build_option_parser().parse_args()

config = brcoti_core.Config(opts)
config.load_file("/etc/pybuilder.json")
for config_path in opts.config:
	config.load_file(config_path)

if opts.action == 'prep':
	if not opts.packages:
		print("Nothing to be done.")
		exit(0)

	exit_code = prep_action(config, opts)
elif opts.action == 'submit':
	if not opts.packages:
		print("Nothing to be done.")
		exit(0)

	exit_code = submit_action(config, opts)
elif opts.action == 'build':
	if not opts.packages:
		print("Nothing to be done.")
		exit(0)

	exit_code = build_action(config, opts)
elif opts.action == 'make-index':
	exit_code = mkindex_action(config, opts)
elif opts.action == 'merge-extra':
	exit_code = merge_extra_action(config, opts)
else:
	raise NotImplementedError("Action %s not yet implemented" % opts.action)
exit(exit_code)
