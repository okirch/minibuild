#!/usr/bin/python3

import sys
import os
import os.path
import io
import pkginfo
import glob
import shutil

def getinfo_pkginfo(path):

	if path.endswith(".whl"):
		return pkginfo.Wheel(path)

	if os.path.isdir(path):
		return pkginfo.UnpackedSDist(path)

	return pkginfo.SDist(path)
	
def getinfo_setuptools(path):
	path = os.path.join(path, 'setup.py')
	if not os.path.exists(path):
		return None

	setup_args = None

	def my_setup(**kwargs):
		nonlocal setup_args
		setup_args = kwargs

	import setuptools

	setuptools.setup = my_setup

	import importlib.util
	spec = importlib.util.spec_from_file_location('setup', path)
	mod = importlib.util.module_from_spec(spec)
	spec.loader.exec_module(mod)

	print("setup() called with args", setup_args.keys())

	mapping = {
		'author' : 'author',
		'author_email' : 'author_email',
		'classifiers' : 'classifiers',
		'keywords' : 'keywords',
		'license' : 'license',
		'url' : 'home_page',
		'description' : 'summary',
		'long_description' : 'description',
		'long_description_content_type' : 'description_content_type',

		'python_requires' : 'requires_python',
		'setup_requires' : 'requires',
		# 'tests_require' : 'requires',
		# 'extras_require' : 'requires'
	}

	d = pkginfo.Distribution()
	for (key, attr) in mapping.items():
		value = setup_args.get(key)
		if value:
			existing = getattr(d, attr, None)
			if existing is not None:
				if type(existing) == list or type(value) == list:
					value = list(existing) + list(value)
				else:
					value = existing + value
			setattr(d, attr, value)

	return d

def pkginfo_as_dict(pkg):
	attrs = []
	for a in dir(pkg):
		if not a.startswith("_"):
			attrs.append(a)

	result = dict()
	for k in attrs:
		v = getattr(pkg, k, None)
		if v is None:
			continue
		if callable(v):
			continue
		result[k] = v

	return result

def pkginfo_print(pkg):
	attrs = []
	for a in dir(pkg):
		if not a.startswith("_"):
			attrs.append(a)

	for k in attrs:
		v = getattr(pkg, k, None)
		if v is None:
			continue
		if callable(v):
			continue

		k = k.capitalize() + ":"
		if type(v) not in (tuple, list):
			v = repr(v)
			if len(v) > 100:
				v = v[:100] + "..."
			print("%-20s  %s" % (k, v))
		elif len(v) == 0:
			# print("%-20s  %s" % (k, "<empty>"))
			continue
		else:
			print("%s" % (k))
			for vi in v:
				print("        %s" % vi)

def pkginfo_as_metadata(pkg):
	def name_to_header(s):
		# strip off trailing plural "s"
		if s in ('classifiers', 'supported_platforms', 'project_urls'):
			s = s[:-1]
		s = (n.capitalize() for n in s.split('_'))
		return "-".join(s)

	def maybe_print(key):
		nonlocal info
		nonlocal seen

		header = name_to_header(key)
		seen.add(key)

		res = header + ": "

		value = info.get(key)
		if value is None:
			return ""

		if type(value) not in (tuple, list):
			if type(value) != str:
				value = repr(value)

			if '\n' in value:
				res += "\n        ".join(value.split('\n'))
			else:
				res += value
		else:
			# Turn classifiers list into several "Classifier:" header lines
			if "Url" in header:
				header = header.replace('Url', "URL")

			res = "\n".join("%s: %s" % (header, v) for v in value)

		if res:
			res += "\n"
			# print(">> %s" % res)
		return res

	seen = set()
	first = ('metadata_version', 'name', 'version', 'summary', 'home_page', 'author', 'author_email', 'maintainer', 'maintainer_email', 'license')
	ignore = ('filename', 'description', 'description_content_type')

	info = pkginfo_as_dict(pkg)

	result = ""
	for key in first:
		result += maybe_print(key)

	for key in sorted(info.keys()):
		if key in seen or key in ignore:
			continue
		result += maybe_print(key)

	result += maybe_print('description_content_type')

	if pkg.description:
		result += "\n" + pkg.description

	return result

def get_python_version():
	vi = sys.version_info
	return "%d.%d.%d" % (vi.major, vi.minor, vi.micro)

def check_python_version(requires_python):
	# We could also use Marker('python_version %s').evaluate()
	from packaging.specifiers import SpecifierSet

	spec = SpecifierSet(requires_python, prereleases = False)
	pyvers = get_python_version()
	return pyvers in spec

def is_version_more_recent(older, newer):
	from packaging.specifiers import parse

	older = parse(older)
	spec = SpecifierSet(requires_python, prereleases = False)
	pyvers = get_python_version()
	return pyvers in spec

def canonical_package_name(name):
	return name.replace('_', '-')

class PackageBuildInfo(object):
	def __init__(self, name, version = None, type = None):
		self.name = name.replace('_', '-')
		self.version = version
		self.type = type

		self.fullreq = None
		self.url = None
		self.filename = None
		self.local_path = None
		self.hash = {}

	def id(self):
		if not self.version:
			return self.name
		return "%s-%s" % (self.name, self.version)

	def add_hash(self, algo, md):
		# print("%s %s=%s" % (self.filename, algo, md))
		self.hash[algo] = md

	def update_hash(self, algo):
		import hashlib

		m = hashlib.new(algo)
		with open(self.local_path, "rb") as f:
			m.update(f.read())

		self.add_hash(algo, m.hexdigest())

	# We should introduce an uploader class for this
	def upload(self, reponame):
		assert(self.local_path)

		print("Uploading %s to %s repository" % (self.local_path, reponame))
		cmd = "twine upload --verbose --repository %s %s" % (reponame, self.local_path)

		print("Running %s" % cmd)
		if os.system(cmd) != 0:
			raise ValueError("Command `%s' returned non-zero exit status" % cmd)

	@staticmethod
	def parse_filename(filename):
		# try to detect version and type by looking at the file name
		_name = filename
		if filename.endswith(".tar.gz"):
			_name = filename[:-7]
			_name, _version = _name.rsplit('-', 1)
			_type = 'sdist'
		elif filename.endswith(".whl"):
			_name, _version, _crap = filename.split('-', 2)
			_type = 'bdist_wheel'
		else:
			raise ValueError("Unable to parse file name \"%s\"" % _name)

		return _name, _version, _type

	@staticmethod
	def from_local_file(path, name = None, version = None, type = None):
		filename = os.path.basename(path)

		if not name or not version or not type:
			# try to detect version and type by looking at the file name
			_name, _version, _type = PackageBuildInfo.parse_filename(filename)

			if name:
				assert(name == _name)
			name = _name
			if version:
				assert(version == _version)
			version = _version
			if type:
				assert(type == _type)
			type = _type

		build = PackageBuildInfo(name, version, type)
		build.filename = filename
		build.local_path = path

		build.update_hash('md5')
		build.update_hash('sha256')

		return build

class PackageReleaseInfo(object):
	def __init__(self, name, version, parsed_version = None):
		self.name = canonical_package_name(name)
		self.version = version

		if not parsed_version:
			from packaging.specifiers import parse
			parsed_version = parse(version)

		self.parsed_version = parsed_version

		self.python_version = None

		self.builds = []

	def id(self):
		return "%s-%s" % (self.name, self.version)

	def more_recent_than(self, other):
		assert(isinstance(other, PackageReleaseInfo))
		return other.parsed_version < this.parsed_version

	def add_build(self, build):
		self.builds.append(build)

	def build_types(self):
		return [b.type for b in self.builds]

class PackageInfo(object):
	def __init__(self, name):
		self.name = canonical_package_name(name)
		self.releases = []

	def add_release(self, release):
		self.releases.append(release)

	def versions(self):
		return [r.version for r in self.releases]

class DownloadFinder(object):
	def __init__(self, req_string, verbose):
		from packaging.requirements import Requirement

		req = Requirement(req_string)
		self.requirement = req

		self.name = req.name
		self.allow_prereleases = False
		self.request_specifier = None
		self.verbose = verbose

	def python_version_check(self, build):
		if not build.python_version:
			return True
		return check_python_version(build.python_version)

	def release_match(self, release):
		if not self.python_version_check(release):
			return False

		assert(release.parsed_version)
		if not self.allow_prereleases and release.parsed_version.is_prerelease:
			return False

		if self.request_specifier and release.parsed_version not in self.request_specifier:
			return False

		return True

	def get_best_match(self, index):
		info = index.get_package_info(self.name)

		if self.verbose:
			print("%s versions: %s" % (self.name, ", ".join(info.versions())))

		best_ver = None
		best_match = None

		for release in info.releases:
			if not self.release_match(release):
				if self.verbose:
					print("ignoring release %s" % release.id())
				continue

			if best_ver and release.parsed_version <= best_ver:
				continue

			for build in release.builds:
				if self.build_match(build):
					best_match = build
					best_ver = release.parsed_version

		if not best_match:
			raise ValueError("%s: unable to find a release that is compatible with my python version" % self.name)

		if self.verbose:
			print("Using %s" % best_match.id())

		return best_match

class SourceDownloadFinder(DownloadFinder):
	def __init__(self, req_string, verbose = False):
		super(SourceDownloadFinder, self).__init__(req_string, verbose)

	def build_match(self, build):
		# print("inspecting %s which is of type %s" % (build.filename, build.type))
		return build.type == 'sdist'

class BinaryDownloadFinder(DownloadFinder):
	def __init__(self, req_string, verbose = False):
		super(BinaryDownloadFinder, self).__init__(req_string, verbose)

	def build_match(self, build):
		# print("inspecting %s which is of type %s" % (build.filename, build.type))
		return build.type == 'bdist_wheel'

class PackageIndex(object):
	def __init__(self, url):
		self.url = url
		self._pkg_url_template = None

	def get_package_info(self, name):
		import urllib.request

		url = self._pkg_url_template.format(index_url = self.url, pkg_name = name)

		resp = urllib.request.urlopen(url)
		if resp.status != 200:
			raise ValueError("Unable to get package info for %s: HTTP response %s (%s)" % (
					name, resp.status, resp.reason))

		return self.process_package_info(name, resp)

class JSONPackageIndex(PackageIndex):
	def __init__(self, url = 'https://pypi.org/pypi'):
		super(JSONPackageIndex, self).__init__(url)
		self._pkg_url_template = "{index_url}/{pkg_name}/json"

	# JSON contains
	# ['info', 'last_serial', 'releases', 'urls']
	# info is a dict of PKG-INFO stuff
	# last_serial is an int, not sure what for
	def process_package_info(self, name, resp):
		from packaging.specifiers import parse
		import json

		info = PackageInfo(name)

		d = json.load(resp)
		for (ver, files) in d['releases'].items():
			relInfo = PackageReleaseInfo(name, ver)
			info.add_release(relInfo)

			for download in files:
				filename = download['filename']

				if download['yanked']:
					print("Ignoring %s: yanked (%s)" % (filename, download['yanked_reason']))
					continue

				type = download['packagetype']
				if type == 'sdist':
					if download['python_version'] != 'source':
						raise ValueError("%s: unable to deal with sdist package w/ version \"%s\"" % (download['filename'], download['python_version']))
					pkgInfo = PackageBuildInfo(name, ver, type = type)
				elif type.startswith('bdist'):
					pkgInfo = PackageBuildInfo(name, ver, type = type)
				else:
					print("%s: don't know how to deal with package type \"%s\"" % (filename, type))
					continue

				pkgInfo.filename = filename
				pkgInfo.url = download['url']

				md = download.get('md5_digest')
				if md:
					pkgInfo.add_hash('md5', md)
				for algo, md in download['digests'].items():
					pkgInfo.add_hash(algo, md)

				relInfo.add_build(pkgInfo)

		return info

# For now, this is a very trivial downloader.
# This could be something much more complex that uses caches, OBS, yadda yadda
class Downloader(object):
	def __init__(self):
		pass

	def download(self, build):
		import urllib.request

		if build.local_path:
			return build.local_path

		assert(build.url)
		assert(build.filename)

		url = build.url
		resp = urllib.request.urlopen(url)
		if resp.status != 200:
			raise ValueError("Unable to download %s from %s (HTTP status %s %s)" % (
					build.filename, url, resp.status, resp.reason))

		filename = build.filename
		with open(filename, "wb") as f:
			f.write(resp.read())

		print("Downloaded %s from %s" % (filename, url))

		build.local_path = filename
		return filename

class WheelArchive(object):
	def __init__(self, path):
		self.path = path
		self._zip = self.open()

	def open(self):
		import zipfile

		return zipfile.ZipFile(self.path, mode = 'r')

	@property
	def basename(self):
		return os.path.basename(self.path)

	def name_set(self):
		result = set()
		for member in self._zip.infolist():
			if member.is_dir():
				continue

			result.add(member.filename)

		return result

	def compare(self, other):
		my_name_set = self.name_set()
		other_name_set = other.name_set()

		added_set = other_name_set - my_name_set
		removed_set = my_name_set - other_name_set

		changed_set = set()
		for member_name in my_name_set.intersection(other_name_set):
			my_data = self._zip.read(member_name)
			other_data = other._zip.read(member_name)

			if other_data != my_data:
				changed_set.add(member_name)

		if False:
			print("added=" + ", ".join(added_set))
			print("removed=" + ", ".join(removed_set))
			print("changed=" + ", ".join(changed_set))

		return added_set, removed_set, changed_set

class Package(object):
	def __init__(self, build):
		assert(build.filename)

		self._source = build
		self._info = getinfo_pkginfo(self.path)

		self.build_dir = "BUILD"
		self._unpacked_dir = None
		self.build_requires = []
		self.artefacts = []

	@property
	def name(self):
		return self._info.name

	@property
	def version(self):
		return self._info.version

	@property
	def path(self):
		return self._source.local_path

	@property
	def NV(self):
		return "%s-%s" % (self.name, self.version)

	def get_hash(self, md):
		import hashlib

		m = hashlib.new(md)
		with open(self.local_path, "rb") as f:
			m.update(f.read())

		return m.hexdigest()

	def print_info(self):
		pkginfo_print(self._info)

	def run(self, cmd):
		print("Running %s" % cmd)
		if os.system(cmd) != 0:
			raise ValueError("Command `%s' returned non-zero exit status" % cmd)

	def check_python(self):
		requires_python = self._info.requires_python
		if not requires_python:
			# any python version is okay
			return

		if not check_python_version(requires_python):
			raise ValueError("Cannot build %s: requires python_version %s" % (self.NV, requires_python))

		print("OK: satisfied python_version requirement %s" % (requires_python))

	def rebuild_required(self, savedir, index):
		if not os.path.exists(savedir):
			return True

		req_list = self.parse_build_requires(savedir)
		for req in req_list:
			if req.fullreq:
				finder = BinaryDownloadFinder(req.fullreq)
			else:
				finder = BinaryDownloadFinder(req.name)

			print("%s requires %s" % (self.name, finder.requirement))

			p = finder.get_best_match(index)

			print("  Best match available from package index: %s" % p.filename)
			if req.version:
				if req.version != p.version:
					print("Building would pick %s-%s rather than %s-%s" % (
						p.name, p.version,
						req.name, req.version))
					return True

			match = False
			for algo, md in req.hash.items():
				print("  We are looking for %s %s %s" % (req.id(), algo, md))
				have_md = p.hash.get(algo)
				if have_md is None:
					print("  => index does not provide %s hash for %s" % (algo, p.filename))
					continue

				print("  => index provides %s %s %s" % (p.filename, algo, p.hash.get(algo)))
				if have_md == md:
					match = True

			if not match:
				print("%s was apparently rebuilt in the meantime, we need to rebuild" % p.filename)
				return True

			print("Build requirement did not change")

		return False

	def unpack(self, git = False):
		archive = self.path
		if os.path.exists(self.build_dir):
			shutil.rmtree(self.build_dir)

		if not git:
			shutil.unpack_archive(archive, self.build_dir)
			self._unpacked_dir = os.path.join(self.build_dir, self.NV)
		else:
			self.unpack_git()
		print("Unpacked %s to %s" % (archive, self._unpacked_dir))

	def unpack_git(self):
		git_repo = self._info.home_page
		git_repo = git_repo.replace('_', '-')
		if not git_repo or not "github.com" in git_repo:
			raise ValueError("Package homepage \"%s\" doesn't look like a git repo" % git_repo)

		self._unpacked_dir = os.path.join(self.build_dir, self.NV)
		self.run("git clone %s %s" % (git_repo, self._unpacked_dir))

		cwd = os.getcwd()
		try:
			os.chdir(self._unpacked_dir)
			self.run("git checkout %s" % self.version)
		finally:
			os.chdir(cwd)

	def build(self, quiet = False):
		assert(self._unpacked_dir)

		cwd = os.getcwd()
		try:
			os.chdir(self._unpacked_dir)
			return self._do_build(quiet)
		finally:
			os.chdir(cwd)
	
	def _do_build(self, quiet):
		cmd = "python3 setup.py bdist_wheel"
		cmd = "pip3 wheel --wheel-dir dist ."
		cmd += " --log pip.log"
		cmd += " --no-deps"

		if quiet:
			cmd += " >build.log 2>&1"
		else:
			cmd += " 2>&1 | tee build.log"

		self.run(cmd)

		wheels = glob.glob("dist/*.whl")
		print("Successfully built %s-%s: %s" % (pkg.name, pkg.version, ", ".join(wheels)))

		for w in wheels:
			w = os.path.join(os.getcwd(), w)

			build = PackageBuildInfo.from_local_file(w)

			for algo in ('md5', 'sha256'):
				build.update_hash(algo)

			self.artefacts.append(build)

		return self.artefacts

	def unchanged_from_previous_build(self, savedir):
		samesame = True
		for wheel in self.artefacts:
			wheel_name = os.path.basename(wheel.local_path)
			old_wheel_path = os.path.join(savedir, wheel_name)
			print("Checking %s vs %s" % (wheel.local_path, old_wheel_path))
			if not os.path.exists(old_wheel_path):
				print("%s does not exist" % old_wheel_path)
				samesame = False
				continue

			old_wheel = WheelArchive(old_wheel_path)
			new_wheel = WheelArchive(wheel.local_path)
			if not self.wheels_identical(old_wheel, new_wheel):
				print("%s differs from previous build" % wheel_name)
				samesame = False
				continue

		path = os.path.join(savedir, "build-requires")
		if not os.path.exists(path):
			print("Previous build of %s did not write a build-requires file" % self.name)
			samesame = False
		else:
			build_req_string = io.StringIO()
			self.write_build_requires(build_req_string)

			with open(path, "r") as f:
				if f.read() != build_req_string:
					print("Build requirements changed")
					samesame = False

		return samesame

	def wheels_identical(self, old_wheel, new_wheel):
		def print_delta(wheel, how, name_set):
			print("%s: %s %d file(s)" % (wheel.basename, how, len(name_set)))
			for name in name_set:
				print("  %s" % name)

		added_set, removed_set, changed_set = old_wheel.compare(new_wheel)

		samesame = True
		if added_set:
			print_delta(new_wheel, "added", added_set)
			samesame = False

		if removed_set:
			print_delta(new_wheel, "removed", removed_set)
			samesame = False

		if changed_set:
			print_delta(new_wheel, "changed", changed_set)
			samesame = False

		if samesame:
			print("%s: unchanged" % new_wheel.basename)

		return samesame

	# There must be a smarter way to extract the build requirements than
	# this...
	def guess_build_dependencies(self):
		from packaging.requirements import Requirement
		import re

		logfile = os.path.join(self._unpacked_dir, "pip.log")
		if not os.path.exists(logfile):
			return

		req = None

		self.build_requires = []
		with open(logfile, "r") as f:
			for l in f.readlines():
				# Parse lines like:
				# Added flit_core<4,>=3.0.0 from http://.../flit_core-3.0.0-py3-none-any.whl#md5=7648384867c294a95487e26bc451482d to build tracker
				if req and ('Added' in l) and ('to build tracker' in l):
					from urllib.parse import urldefrag, urlparse

					m = re.search('Added ([^ ]*) from ([^ ]*)', l)
					if not m:
						raise ValueError("regex match failed")

					r = Requirement(m.group(1))
					url = m.group(2)

					# This is needed to deal with some oddities of pip.
					# For instance, package flit requires flit_core. However,
					# pip will change that name to flit-core, and look for it
					# in the index by this name.
					# pypi has both flit_core and flit-core wheels, but they have
					# different hash digests, causing our rebuild checks to
					# fire without need.
					if req.name != r.name:
						r.name = canonical_package_name(r.name)
						assert(req.name == r.name)
					req.fullreq = str(r)

					url, frag = urldefrag(url)
					if frag:
						algo, md = frag.split('=')
						req.add_hash(algo, md)

					req.url = url
					req.filename = os.path.basename(urlparse(url).path)
					continue

				if "to search for versions of" not in l:
					continue

				m = re.search('to search for versions of (.*):', l)
				if not m:
					raise ValueError("regex match failed")

				req = PackageBuildInfo(m.group(1))
				self.build_requires.append(req)

	def save_results(self, savedir):
		if os.path.exists(savedir):
			shutil.rmtree(savedir)
		os.makedirs(savedir, mode = 0o755)

		logfile = os.path.join(self._unpacked_dir, "build.log")
		if os.path.exists(logfile):
			self.save_file(logfile, savedir)

		logfile = os.path.join(self._unpacked_dir, "pip.log")
		if os.path.exists(logfile):
			self.save_file(logfile, savedir)

		self.save_build_requires(savedir)
		self.save_build_artefacts(savedir)

		for wheel in self.artefacts:
			wheel.local_path = self.save_file(wheel.local_path, savedir)

			path = os.path.join(savedir, "%s-METADATA.txt" % wheel.id())
			with open(path, "w") as f:
				print("Writing %s metadata to %s" % (wheel.id(), path))

				pi = getinfo_pkginfo(wheel.local_path)
				f.write(pkginfo_as_metadata(pi))

	def save_build_artefacts(self, savedir):
		path = os.path.join(savedir, "build-artefacts")
		print("Writing %s" % path)
		self.write_build_artefacts(open(path, "w"))

	def write_build_artefacts(self, f):
		for wheel in self.artefacts:
			f.write("wheel %s\n" % wheel.name)
			f.write("  version %s\n" % wheel.version)

			for algo in ('md5', 'sha256'):
				f.write("  hash %s %s\n" % (algo, wheel.hash.get(algo)))

	def save_file(self, src, dst):
		print("Saving %s to %s" % (src, dst))
		shutil.copy(src, dst)

		if os.path.isdir(dst):
			return os.path.join(dst, os.path.basename(src))
		return dst

	def save_build_requires(self, savedir):
		logfile = os.path.join(savedir, "build-requires")
		self.write_build_requires(self, open(logfile, "w"))

	def write_build_requires(self, f):
		for req in self.build_requires:
			f.write("require %s\n" % req.name)
			if req.fullreq:
				f.write("  specifier %s\n" % req.fullreq);
			if req.hash:
				for (algo, md) in req.hash.items():
					f.write("  hash %s %s\n" % (algo, md))

	def parse_build_requires(self, savedir):
		result = []

		path = os.path.join(savedir, "build-requires")
		with open(path, 'r') as f:
			req = None
			for l in f.readlines():
				if not l:
					continue

				if l.startswith("require"):
					name = l[7:].strip()
					req = PackageBuildInfo(name)
					result.append(req)
					continue

				if req is None:
					raise ValueError("%s: no build info in this context" % (path, ))

				if l.startswith(' '):
					words = l.strip().split()
					if not words:
						continue
					if words[0] == 'specifier':
						req.fullreq = words[1]
						continue

					if words[0] == 'hash':
						req.add_hash(words[1], words[2])
						continue

				raise ValueError("%s: unparseable line <%s>" % (path, l))

		return result

	def get_metadata(self):
		return pkginfo_as_metadata(self._info)

def build_option_parser():
	import optparse

	parser = optparse.OptionParser(usage = "blah")
	parser.add_option('--debug', default = False, action = 'store_true',
                help = "Enable debugging output")
	parser.add_option('--quiet', default = False, action = 'store_true',
                help = "Be less verbose")
	parser.add_option('--git', default = False, action = 'store_true',
                help = "Build from git repo rather than sdist")
	parser.add_option('--rebuild-if-needed', default = False, action = 'store_true',
                help = "Only rebuild package if needed")
	parser.add_option('--force', default = False, action = 'store_true',
                help = "Always store build results, even if they did not change")

	parser.add_option('--output-dir', default = "OUTPUT",
		help = "Directory to write output files to (defaults to OUTPUT)")
	parser.add_option('--upload-to', default = None,
		help = "Repository to upload packages to")

	return parser

(opts, args) = build_option_parser().parse_args()

if False:
	index_url = 'http://localhost:8081/repository/pypi-group/'
	packageIndex = JSONPackageIndex(url = index_url)
else:
	packageIndex = JSONPackageIndex()

downloader = Downloader()

for file in args:
	print("Examining %s" % file)

	if os.path.exists(file):
		build = PackageBuildInfo.from_local_file(file)
	else:
		finder = SourceDownloadFinder(file, verbose = True)
		build = finder.get_best_match(packageIndex)

	print("=== Package %s ===" %(build.id()))

	if not build.local_path:
		downloader.download(build)

	pkg = Package(build)
	pkg.check_python()

	try:
		savedir = os.path.join(opts.output_dir, pkg.NV)

		if opts.rebuild_if_needed:
			print("=== Checking whether a rebuild is required ===")
			if not pkg.rebuild_required(savedir, packageIndex):
				print("=== No rebuild required for %s ===" %(pkg.NV))
				continue

		print("=== Unpacking %s ===" %(pkg.NV))
		pkg.unpack(git = opts.git)

		print("=== Building %s ===" %(pkg.NV))
		built = pkg.build(quiet = opts.quiet)

		if not built:
			raise ValueError("%s: nothing got built" % file)

		print("=== Inspecting build dependencies ===")
		pkg.guess_build_dependencies()

		for req in pkg.build_requires:
			for algo in ('md5', 'sha256'):
				if req.hash.get(algo) is None:
					print("WARNING: No %s hash for %s" % (algo, req.name))
					downloader.download(req)
					req.update_hash(algo)

		if pkg.build_requires:
			print("Build requirements:")
			pkg.write_build_requires(sys.stdout)


		print("=== Checking whether artefacts changed from previous build ===")
		if not opts.force and pkg.unchanged_from_previous_build(savedir):
			print("%s artefacts have not changed since previous build" % pkg.NV)
			continue

		print("=== Storing build results ===")
		pkg.save_results(savedir)

		if opts.upload_to:
			print("=== Uploading build results to %s ===" % opts.upload_to)
			for p in built:
				p.upload(opts.upload_to)
		else:
			print("=== Leaving build results in %s ===" % savedir)
			for p in built:
				print("Built %s as %s" % (p.NV, p.path))

	except Exception as e:
		print("FAILED to build %s" % pkg.NV)
		import traceback
		print(e)
		traceback.print_tb(sys.exc_info()[2])
		traceback.format_exc()

print("=== Done ===")
