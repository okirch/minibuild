#!/usr/bin/python3
#
# This is a simplistic build script for building artefacts of various
# programming languages natively (eg using pip, npm etc) and upload the
# resulting artefacts to a local repo.
#
#   Copyright (C) 2020 Olaf Kirch <okir@suse.de>
#
#   This program is free software; you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation; either version 2 of the License, or
#   (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
#

import sys
import os
import os.path
import io
import pkginfo
import glob
import shutil
import brcoti_core

SCRIPT_NAME = sys.argv[0]

DEFAULT_BUILD_COMPUTE = "podman"

def create_build_engine(config):
	opts = config.command_line_options
	return brcoti_core.Engine.factory(opts.engine)

def create_compute_backend(config, default_backend):
	backend_name = config.command_line_options.compute or default_backend
	return brcoti_core.Compute.factory(backend_name, config)

def source_from_path(name, config):
	if os.path.isdir(name):
		print("=== Using source directory %s ===" % name)
		return brcoti_core.Engine.create_source_from_local_directory(name, config)

	engine = create_build_engine(config)

	print("=== Using file %s (build engine %s) ===" % (name, engine.name))
	source = engine.create_source_from_local_file(name)

	# DownloadFinder will never return an sdist that
	# requires a python version incompatible with ours.
	# For an sdist provided directly on the command line,
	# it might be nice to check for this explicitly, but that's a
	# lot of work. Not the least because many sdist tarballs
	# do not contain structured build information, but provide
	# a more or less messy setup.py

	return source

def find_source(engine, req_string, use_git = True, git_url = None, git_tag = None, version = None):
	print("=== Locating %s ===" % (req_string,))

	if use_git and (req_string.startswith("https:") or req_string.startswith("http:")):
		if git_url:
			raise ValueError("I'm confused. You specified \"%s\" as package name, and provided a --git-url as well" % req_string)
		git_url = req_string
		req_string = None

	if use_git and git_url:
		sdist = engine.create_artefact_from_url(git_url, version = version, package_name = req_string, tag = git_tag)
	else:
		if version:
			req_string = "%s == %s" % (req_string, version)
		req = engine.parse_build_requirement(req_string)
		sdist = engine.build_source_locate(req)

	if sdist is None:
		print("FAILED to locate source for %s" % req)
		return None

	# By default, if the engine finds that a source artefact comes
	# with a git url, it will try to build directly from git.
	if not use_git:
		sdist.git_repo_url = None

	return brcoti_core.SourceFile(sdist, engine)

class BuildJob(object):
	def __init__(self, config, engine, compute_backend, source):
		self.config = config
		self.engine = engine
		self.compute_backend = compute_backend
		self.source = source
		self.build = None
		self.build_state = self.engine.build_state_factory(source)

		build_strategy = self.source.spec.build_strategy
		if build_strategy is None:
			build_strategy = self.engine.create_build_strategy_default()
		self.build_strategy = build_strategy

		build_strategy.resolve_source(self.source)

		self.always_commit = False
		self.quiet = False
		self.rebuild_if_needed = False
		self.shell_on_fail = False
		self.auto_repair = False
		self.ignore_implicit_dependencies = False

	def id(self):
		return self.source.id()

	def source_for(self, build):
		spec = self.source.spec

		assert(len(spec.sources) >= 1)
		return spec.sources[0]

	def rebuild_required(self):
		if not self.rebuild_if_needed:
			return True

		print("=== Checking whether a rebuild is required ===")
		if not self.build_state.rebuild_required():
			print("=== No rebuild required for %s ===" % self.id())
			return False

		return True

	# This is a prep task
	# Merge explicit requirements given on the command line as
	#  --require rpm:foo,bar,baz --require ruby:bundler,rake
	def merge_cmdline_requirements(self, opt_list):
		spec = self.source.spec

		for s in opt_list:
			if ':' not in s:
				raise ValueError("--require argument must be of the form \"engine:name,name,...\" (%s)" % s)

			(engine_name, rest) = s.split(':', 1)

			engine = brcoti_core.Engine.factory(engine_name)

			for req in rest.split(','):
				req = engine.parse_build_requirement(req)
				req.origin = 'commandline'
				spec.add_requirement(req)

	# This is a prep task
	# Set the build strategy from the --strategy command line options, such as
	#  --strategy 'bundler(gem-build())'
	def set_cmdline_strategy(self, arg):
		if not arg or arg == 'auto':
			return

		self.source.spec.build_strategy = brcoti_core.BuildStrategy.parse(self.engine, arg)
		self.build_strategy = self.source.spec.build_strategy

	# This is a prep task - eg ruby would look at the upstream artefact
	# and scan it for :development dependencies
	def anticipate_build_dependencies(self):
		spec = self.source.spec

		dep_list = []
		for sdist in spec.sources:
			print("Retrieving implicit build requirements for %s" % sdist.id())
			dep_list += self.engine.infer_build_requirements(sdist)

		if dep_list:
			print("Inferred build requirement(s) from package:")
			for dep in dep_list:
				print("  %s" % dep.format())
				spec.add_requirement(dep)


	def unpack_source(self):
		print("=== Unpacking %s ===" % self.id())
		build_spec = self.source.spec
		build_strategy = self.build_strategy

		print("Validating build info")
		self.engine.validate_build_spec(build_spec, auto_repair = self.auto_repair)

		# Download the source archive if we don't have it yet
		for sdist in build_spec.sources:
			# FIXME: how do we make sure we use the right downloader here? 
			if sdist.url and not sdist.git_url():
				self.engine.downloader.download(sdist)

		# spawn a container/VM or whatever compute node we need
		compute_node = self.engine.prepare_environment(self.compute_backend, build_spec)

		try:
			self.build = self.engine.create_build_directory(compute_node)

			# Unpack the first source
			# (if we ever support builds with more than one source, we have to
			# revisit this).
			self.build.unpack(build_spec, build_spec.sources[0])

			requirements = build_strategy.implicit_build_dependencies(self.build)

			if not self.ignore_implicit_dependencies:
				missing = self.build.engine.validate_build_requirements(requirements, merge_from_upstream = self.auto_repair)
				if missing:
					raise brcoti_core.UnsatisfiedDependencies("Build has unsatisfied dependencies", missing)

		except brcoti_core.UnsatisfiedDependencies as e:
			print("Cannot build %s: missing build dependencies:" % self.id())
			for req in e.dependencies:
				print("  %s" % req.format())

			if e.remedy:
				print("")
				print("Suggested remedy")
				e.remedy.display()

			raise e

		# When cloning a git repo, we perform auto-detection of tags (in order
		# to find the tag corresponding to the version we want to build).
		# So as we get here, a git based source may suddenly have a tag assigned
		# that did not have one before.
		if build_spec.tag is None and len(build_spec.sources) == 1:
			sdist = build_spec.sources[0]
			if sdist.version == build_spec.version:
				build_spec.tag = sdist.git_tag()

		self.build.set_logging(self.quiet, self.build_state.build_log_file())
		return self.build

	def build_package(self):
		print("=== Building %s ===" % self.id())
		build = self.build
		build_strategy = self.build_strategy

		try:
			artefacts = build.build(build_strategy)
		except brcoti_core.BuildFailure as e:
			if not self.shell_on_fail:
				raise e

			print("*** BUILD FAILURE ***")
			print(e)
			print("Opening interactive shell for debugging")
			self.build.compute.interactive_shell(working_dir = e.cmd.working_dir)
			raise brcoti_core.BuildAborted()

		if not artefacts:
			if not self.shell_on_fail:
				raise ValueError("%s: nothing got built" % self.source.id())

			print("*** BUILD DID NOT PRODUCE ANY OUTPUT ***")
			print("Opening interactive shell for debugging")
			self.build.compute.interactive_shell(working_dir = build.directory)
			raise brcoti_core.BuildAborted()

		return artefacts

	def process_build_dependencies(self):
		print("=== Inspecting build dependencies ===")
		build = self.build

		build.guess_build_dependencies(self.build_strategy)

		requires = self.engine.finalize_build_depdendencies(build)

		if requires:
			print("Build requirements:")
			for req in requires:
				print("  %s" % (req, ))
				self.source.spec.add_requirement(req)

	def prepare_results(self):
		print("=== Collecting build results ===")
		build = self.build

		build.prepare_results(self.build_state)

	def compare_upstream(self):
		print("=== Comparing our build to upstream artefact(s) ===")
		engine = self.engine
		build = self.build

		retval = True
		for mine in build.build_info.artefacts:
			# The version of the artefact we built may not be what we
			# started with. Some gems append the build date to the
			# package version. In other cases (eg when building a compiled
			# native ruby extension), the version will include the platform
			# (such as x86_linux)
			#
			# Therefore, we need to use the version number of the package
			# we started from.
			sdist = self.source_for(mine)

			upstream = engine.get_upstream_build_for(sdist, mine)
			if upstream is None:
				print("    Skipping %s" % mine.filename)
				continue

			if upstream.id() != mine.id():
				print("  Comparing %s to upstream %s" % (mine.id(), upstream.id()))
			assert(mine.platform == upstream.platform)

			# The artefact was returned by an index; it's a bug to not be attached
			# the a cache
			assert(upstream.cache)

			path = engine.downloader.download(upstream)

			# This returns an ArtefactComparison object
			changes = build.compare_build_artefacts(path, mine.local_path)

			if changes:
				# Our build is identical with upstream
				continue

			print("%s differs from upstream build" % mine.id())
			self.display_upstream_changes(changes)

			with self.build_state.open_file("upstream-diff", "Diff versus upstream") as f:
				saved_stdout = sys.stdout
				sys.stdout = f
				print("Difference from upstream build")
				self.display_upstream_changes(changes)
				sys.stdout = saved_stdout

			retval = False

		if retval:
			print("Our build matches upstream")
		return retval

	def display_upstream_changes(self, changes):
		changes.print()

		print("--- showing diff ---")
		changes.show_diff()
		print("--- end diff ---")
		print("")

	# This is a prep task.
	# After a successful build, we inspect the list of packages that got installed
	# automatically (eg via pip wheel or bundler install) and check them against
	# our local index.
	def verify_artefact_availability(self, artefact_list):
		self.engine.validate_used_packages(artefact_list, merge_from_upstream = self.auto_repair)

	def maybe_commit(self):
		print("=== Checking whether artefacts changed from previous build ===")
		build_state = self.build_state
		build = self.build

		if not self.always_commit and build.unchanged_from_previous_build(build_state):
			print("Artefacts have not changed since previous build")
			return

		uploader = self.engine.uploader
		if uploader:
			print("=== Uploading build results to %s ===" % uploader.describe())
			for p in build.artefacts:
				uploader.upload(p)

		build_state.commit()
		build.cleanup()

		build_state.cleanup()
		self.build_state = None

def upstream_check_failed():
	warnmsg = '''

        W   W    A    RRR  N   N II N   N  GGG   !!
        W   W   A A   R  R NN  N II NN  N G      !!
        W W W  AAAAA  RRR  N N N II N N N G  GG  !!
         W W  A     A R  R N  NN II N  NN  GGG   **

Our build seems to differ from the upstream build, which most likely means we did not
build it correctly.
If our build *IS* correct, and this warning is due to a bug, please fix the mis-detection.
If you're in a hurry, re-run this command with --no-upstream-check
'''
	print("=== WARNING: DIFFERS FROM UPSTREAM ===")
	print(warnmsg)
	print("=== WARNING: DIFFERS FROM UPSTREAM ===")

def prep_action(config, opts):
	engine = create_build_engine(config)

	# Allow to override on the command line?
	compute_backend = create_compute_backend(config, DEFAULT_BUILD_COMPUTE)

	exit_code = 0
	for name in opts.packages:
		# We want to build using upstream. This selects the upstream package repo
		# and disables the proxy.
		engine.use_upstream()

		if os.path.isfile(name):
			source = source_from_path(name, config)
		else:
			source = find_source(engine, name, use_git = opts.git, git_url = opts.git_url, git_tag = opts.git_tag, version = opts.version)
		if source is None:
			exit_code = 1
			continue

		sdist = source.spec.sources[0]

		if name != sdist.name:
			print("Package name is %s" % sdist.name)
			name = sdist.name

		url = sdist.git_url()
		if not url:
			url = sdist.url
		if url:
			print("Building %s from %s" % (sdist.id(), url))

		source.spec._build_strategy = engine.create_build_strategy("auto")

		print("=== Package %s ===" %(source.id()))
		job = BuildJob(config, engine, compute_backend, source)
		job.quiet = opts.quiet
		job.shell_on_fail = opts.shell_on_fail
		job.auto_repair = opts.auto_repair
		job.ignore_implicit_dependencies = opts.ignore_implicit_dependencies

		job.merge_cmdline_requirements(opts.require)
		job.set_cmdline_strategy(opts.strategy)

		try:
			if not opts.ignore_package_dependencies:
				job.anticipate_build_dependencies()

			job.unpack_source()
			job.build_package()
			job.process_build_dependencies()
			job.prepare_results()
			if opts.no_upstream_check:
				print("*** Skipping upstream check. ***")
			elif not job.compare_upstream():
				upstream_check_failed()
				exit_code = 1

			# job.maybe_commit()

		except brcoti_core.BuildAborted:
			print("Build of %s ABORTED" % sdist.id())
			exit_code = 1
		except Exception as e:
			print("FAILED to build %s" % sdist.id())
			import traceback
			print(e)
			traceback.print_tb(sys.exc_info()[2])
			traceback.format_exc()
			exit_code = 1

		if job.build:
			write_source_dir(name, source, job.build)

			engine.reset_indices()
			job.verify_artefact_availability(job.build.build_info.used)

	print("=== Done ===")

	# In case anyone would ever entertain the idea of mixing calls to prep_action
	# with other actions within a single run.
	engine.reset_indices()

	return exit_code

def zap_source_dir(src_dir):
	if os.path.isdir(src_dir):
		shutil.rmtree(src_dir)

def write_source_dir(src_dir, source, build_dir):
	build_info = build_dir.build_info

	zap_source_dir(src_dir)

	source.merge_info_from_build(build_info)

	source.save(src_dir)

	info_path = os.path.join(src_dir, "build-used")
	build_dir.save_build_info(info_path)

def submit_action(config, opts):
	exit_code = 0
	for name in opts.packages:
		print("Examining %s" % name)

		if not os.path.isdir(name):
			print("Cannot submit %s: must be a local directory" % name)
			exit_code = 1
			continue

		print("=== Using source directory %s ===" % name)
		source = brcoti_core.Engine.create_source_from_local_directory(name, config)

		engine = brcoti_core.Engine.factory(source.spec.engine)
		if not engine:
			print("%s: build-info specifies invalid engine \"%s\"" % (name, source.spec.engine))
			exit_code = 1
			break

		engine.submit_source(source)

	print("=== Done ===")
	return exit_code

def build_action(config, opts):
	compute_backend = create_compute_backend(config, DEFAULT_BUILD_COMPUTE)

	exit_code = 0
	for name in opts.packages:
		print("Examining %s" % name)

		source = source_from_path(name, config)
		if source is None:
			exit_code = 1
			continue

		# If we're asked to build a specific version, but that version is not specified in the
		# spec file, pick one that is "close" and base our build description off of it.
		if opts.version and not source.select_version(opts.version):
			if not source.from_closest_version(opts.version):
				raise ValueError("%s does not have version %s, and nothing to guess from" % (name, opts.version))

			source.spec.no_default_patches = opts.no_default_patches

			this_exit_code = build_one_version(compute_backend, source, True)

			if this_exit_code == 0:
				source.save()
			else:
				exit_code = this_exit_code
				print("Non-zero exit code, writing updated spec file to build-spec.new")
				source.save(spec_name = "build-spec.new")
		elif opts.all_versions or opts.all_unbuilt_versions:
			rebuilding = []
			skipped = []

			engine = brcoti_core.Engine.factory(source.spec_file.engine)
			for v in source.spec_file.versions:
				if v.source is not None:
					if not opts.all_versions:
						bs = engine.build_state_factory(v.source)
						if bs.built_previously():
							skipped.append(v)
							continue

					rebuilding.append(v)

			if skipped:
				print("Not rebuilding versions %s" % (
					" ".join([v.version for v in skipped])))

			if not rebuilding:
				print("Nothing to rebuild, we're good")
			else:
				print("Going to (re-)build these versions:")
				for v in rebuilding:
					print("  %s" % v.version)

			for v in rebuilding:
				source.spec = v
				this_exit_code = build_one_version(compute_backend, source)

				if this_exit_code:
					exit_code = this_exit_code
		else:
			this_exit_code = build_one_version(compute_backend, source)

			if this_exit_code:
				exit_code = this_exit_code

		if opts.auto_submit:
			if exit_code != 0:
				print("WARNING: Build was not successful. NOT submitting source code.")
			else:
				engine = brcoti_core.Engine.factory(source.spec_file.engine)
				engine.submit_source(source)

	print("=== Done ===")
	return exit_code

def build_one_version(compute_backend, source, check_package_dependencies = False):
	engine = brcoti_core.Engine.factory(source.spec.engine)

	print("=== Package %s ===" %(source.id()))
	job = BuildJob(config, engine, compute_backend, source)
	job.always_commit = opts.force
	job.quiet = opts.quiet
	job.rebuild_if_needed = opts.rebuild_if_needed
	job.shell_on_fail = opts.shell_on_fail
	job.auto_repair = opts.auto_repair

	# job.merge_cmdline_requirements(opts.require)
	# job.set_cmdline_strategy(opts.strategy)

	exit_code = 0
	try:
		if not job.rebuild_required():
			return 0

		if check_package_dependencies and not opts.ignore_package_dependencies:
			job.anticipate_build_dependencies()

		job.unpack_source()
		job.build_package()
		job.process_build_dependencies()
		job.prepare_results()

		if opts.upstream_check and not job.compare_upstream():
			upstream_check_failed()
			exit_code = 1

		job.maybe_commit()

	except brcoti_core.BuildAborted:
		print("Build of %s ABORTED" % source.id())
		exit_code = 1
	except brcoti_core.UnsatisfiedDependencies as e:
		print("Build of %s has unsatisfied dependencies" % source.id())
		for req in e.dependencies:
			print("  %s" % req.format())

		print("In order to merge these from upstream, run the following command:")
		print("%s merge-extra %s" % (SCRIPT_NAME,
				" ".join(["'%s:%s'" % (r.engine, r.format()) for r in e.dependencies])))
		exit_code = 1
	except Exception as e:
		print("FAILED to build %s" % source.id())
		import traceback
		print(e)
		traceback.print_tb(sys.exc_info()[2])
		traceback.format_exc()
		exit_code = 1

	return exit_code

def mkindex_action(config, opts):
	engine = brcoti_core.Engine.factory(opts.engine)

	print("=== Publishing %s build results ===" % engine.name)
	engine.publish_build_results()

	print("=== Done ===")
	return 0

def merge_extra_action(config, opts):
	by_engine = dict()

	noise_canceling_map = str.maketrans("()", "  ")
	for name in opts.packages:
		if ':' not in name:
			print("argument format should be <engine>:<package> - cannot parse \"%s\"" % name)
			raise ValueError("Cannot parse upstream requirement \"%s\"" % name)

		(engine_name, req_string) = name.split(':', 1)

		req_list = by_engine.get(engine_name)
		if req_list is None:
			req_list = []
			by_engine[engine_name] = req_list

		# In order to make cut'n'paste life easier, translate
		#    floopie (~> 2.7)
		# to
		#    floopie ~> 2.7
		if engine_name == 'ruby':
			 req_string = req_string.translate(noise_canceling_map)

		req_list.append(req_string)

	for (engine_name, req_list) in by_engine.items():
		print("=== Merging %s packages from upstream ===" % engine_name)
		engine = brcoti_core.Engine.factory(engine_name)

		req_list = [engine.parse_build_requirement(req_string) for req_string in req_list]

		engine.validate_build_requirements(req_list, merge_from_upstream = True, recursive = True)
		# engine.publish_build_results()

	print("=== Done ===")
	return 0

def prune_extra_action(config, opts):
	if opts.engine is None:
		raise ValueError("You have to specify a build engine using --engine <NAME>")

	engine = brcoti_core.Engine.factory(opts.engine)
	engine.publish_build_results(prune_extras = True)

def cleanup_action(config, opts):
	for name in opts.packages:
		spec_path = os.path.join(name, "build-spec")
		if os.path.exists(spec_path):
			spec = brcoti_core.BuildSpec.from_file(spec_path)
		else:
			info_path = os.path.join(name, "build-info")
			if not os.path.exists(info_path):
				raise ValueError("No build-spec of build-info in directory %s" % name)

			spec = brcoti_core.BuildSpec.from_file(info_path)

		temp_path = spec_path + ".new"
		spec.save(temp_path)
		print("Wrote spec to %s" % temp_path)

		continue

def build_option_parser():
	import argparse

	parser = argparse.ArgumentParser(prog = "minibuild",
		description = "Build artefacts for various native package managers")

	parser.add_argument('--config', default = [], action = 'append',
		help = "Path to configuration file")

	parser.add_argument('--engine', default = "python3",
		help = "Build engine to use (defaults to python3)")

	parser.add_argument('--debug', default = False, action = 'store_true',
                help = "Enable debugging output")
	parser.add_argument('--quiet', default = False, action = 'store_true',
                help = "Be less verbose")

	parser.add_argument('--compute', default = None,
		help = "Compute backend to use (default is dependent on the action)")

	subparsers = parser.add_subparsers(dest="action",
		title = "action")

	prep_parser = subparsers.add_parser('prep',
		help = "Prepare new source package")

	prep_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")
	prep_parser.add_argument('--git', default = False, action = 'store_true',
                help = "Build from git repo rather than sdist")
	prep_parser.add_argument('--version', default = None,
                help = "Explicitly specify the package version to build from")
	prep_parser.add_argument('--git-url', default = None,
                help = "Explicitly specify the git repo to build from")
	prep_parser.add_argument('--git-tag', default = None,
                help = "Explicitly specify the git tag or commit to build from")
	prep_parser.add_argument('--no-upstream-check', default = False, action = 'store_true',
                help = "Do not compare our build results to upstream build (use with caution)")
	prep_parser.add_argument('--shell-on-fail', default = False, action = 'store_true',
                help = "When a build command fails, open an interactive shell session to debug the issue")
	prep_parser.add_argument('--auto-repair', default = False, action = 'store_true',
                help = "Try to detect and fix build environment issues")
	prep_parser.add_argument('--require', default = [], action = 'append',
                help = "List explicit build dependencies such as 'rpm:gcc-c++'")
	prep_parser.add_argument('--strategy', default = None,
                help = "Specify a build strategy like 'bundler(gem-build())' (default: auto)")
	prep_parser.add_argument('--ignore-package-dependencies', default = False, action = 'store_true',
                help = "When building a new version from an existing build-spec, do not inspect any dependencies listed by the package")
	prep_parser.add_argument('--ignore-implicit-dependencies', default = False, action = 'store_true',
                help = "Ignore dependencies inferred by the build strategy")

	submit_parser = subparsers.add_parser('submit',
		help = "Submit source package(s)")
	submit_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")

	build_parser = subparsers.add_parser('build',
		help = "Build package(s)")
	build_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")
	build_parser.add_argument('--version', default = None,
                help = "Explicitly specify the package version to build from")
	build_parser.add_argument('--all-versions', default = False, action = 'store_true',
                help = "(Re-)build all versions listed in the spec file")
	build_parser.add_argument('--all-unbuilt-versions', default = False, action = 'store_true',
                help = "Build all versions listed in the spec file which have not been built yet")
	build_parser.add_argument('--rebuild-if-needed', default = False, action = 'store_true',
                help = "Only rebuild package if needed")
	build_parser.add_argument('--force', default = False, action = 'store_true',
                help = "Always store build results, even if they did not change")
	build_parser.add_argument('--upstream-check', default = False, action = 'store_true',
                help = "Compare our build results to upstream build (use with caution)")
	build_parser.add_argument('--shell-on-fail', default = False, action = 'store_true',
                help = "When a build command fails, open an interactive shell session to debug the issue")
	build_parser.add_argument('--auto-repair', default = False, action = 'store_true',
                help = "Try to detect and fix build environment issues")
	build_parser.add_argument('--no-default-patches', default = False, action = 'store_true',
                help = "When building a new version from an existing build-spec, ignore any default patches")
	build_parser.add_argument('--ignore-package-dependencies', default = False, action = 'store_true',
                help = "When building a new version from an existing build-spec, do not inspect any dependencies listed by the package")
	build_parser.add_argument('--auto-submit', default = False, action = 'store_true',
                help = "Automatically submit source if the build succeeds (use with caution)")

	mkindex_parser = subparsers.add_parser('make-index',
		help = "Rebuild package index")
	mkindex_parser.add_argument('--destdir', default = None,
		help = "Specify the destination directory (defaults to working directory)")

	merge_parser = subparsers.add_parser('merge-extra',
		help = "Merge extra binary packages from upstream")
	merge_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")

	prune_parser = subparsers.add_parser('prune-extra',
		help = "Prune binary packages from extra index that are no longer required")

	cleanup_parser = subparsers.add_parser('cleanup',
		help = "Clean up source package")
	cleanup_parser.add_argument('packages', metavar = 'PKG', type = str, nargs = '+',
		help = "List of packages")

	return parser

opts = build_option_parser().parse_args()

config = brcoti_core.Config(opts)
config.load_file("/etc/pybuilder.json")
for config_path in opts.config:
	config.load_file(config_path)

if opts.action == 'prep':
	if not opts.packages:
		print("Nothing to be done.")
		exit(0)

	exit_code = prep_action(config, opts)
elif opts.action == 'submit':
	if not opts.packages:
		print("Nothing to be done.")
		exit(0)

	exit_code = submit_action(config, opts)
elif opts.action == 'build':
	if not opts.packages:
		print("Nothing to be done.")
		exit(0)

	exit_code = build_action(config, opts)
elif opts.action == 'make-index':
	exit_code = mkindex_action(config, opts)
elif opts.action == 'merge-extra':
	exit_code = merge_extra_action(config, opts)
elif opts.action == 'prune-extra':
	exit_code = prune_extra_action(config, opts)
elif opts.action == 'cleanup':
	exit_code = cleanup_action(config, opts)
elif opts.action is None:
	raise ValueError("Missing ACTION on command line (try %s --help)" % SCRIPT_NAME)
else:
	raise NotImplementedError("Action %s not yet implemented" % opts.action)
exit(exit_code)
